{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22d0ca30170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Read in Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in Iris Data\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X=     iris.data[:,:]\n",
    "y=     iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and training data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=73)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer to torch tensor \n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Build your network (The structure of the ANN is totally flexible, you can choose different hidden layers, different neurons, different activation functions as long as you are satisfied with test accuracy in step 5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: create an ANN class (If you are familiar with constructing a class, I would suggest you to construct your ANN using a class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example:\n",
    "# class ANN(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super().__init__()\n",
    "#        self.fc1 = nn.Linear(in_features=4, out_features=16)\n",
    "#        self.output = nn.Linear(in_features=16, out_features=3)\n",
    "\n",
    "#    def forward(self, x):\n",
    "#        x = F.relu(self.fc1(x))\n",
    "#        x = self.output(x)\n",
    "#        return x\n",
    "\n",
    "    \n",
    "# class ANN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         ###write your code here###\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         ###write your code here###\n",
    "#         return x\n",
    "    \n",
    "# model = ANN()\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: create network using nn.Sequential()   (If you are not familiar with class, it is fine to connect all layers with nn.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (1): ELU(alpha=1.0)\n",
      "  (2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define network dimensions\n",
    "n_input_dim = X_train.shape[1]\n",
    "# Layer size\n",
    "n_hidden = 4 # Number of hidden nodes\n",
    "n_output = 3 # Number of output nodes (because 3 classes)\n",
    "\n",
    "# Example:\n",
    "model = nn.Sequential(\n",
    "   nn.Linear(n_input_dim, n_hidden),\n",
    "   nn.ELU(),\n",
    "   nn.Linear(n_hidden, n_output),\n",
    "   nn.Sigmoid())\n",
    "\n",
    "print(model)\n",
    "\n",
    "# model=nn.Sequential(\n",
    "#     #####write your code here#####\n",
    "#     )\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Train the network and draw the training loss and training accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sum() received an invalid combination of arguments - got (axis=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: axis, out\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\miche\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2239\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2241\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2242\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\miche\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sum() received an invalid combination of arguments - got (axis=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: axis, out\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 100\n",
    "loss_arr = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_hat =        model(X_train)\n",
    "    loss =         criterion(y_hat, y_train)\n",
    "    \n",
    "    y_hat_class =  np.where(y_hat.detach().numpy()<0.5, 0, 1)\n",
    "    accuracy =     np.sum(y_train.reshape(-1,1)==y_hat_class) / len(y_train)\n",
    "    train_accuracy.append(accuracy)\n",
    "    train_loss.append(loss.item())\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} Loss: {loss}')\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "#plot the training loss and training accuracy\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12,8))\n",
    "ax[0].plot(train_loss)\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Training Loss')\n",
    "\n",
    "ax[1].plot(train_accuracy)\n",
    "ax[1].set_ylabel('Classification Accuracy')\n",
    "ax[1].set_title('Training Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Test Accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = model(X_test)\n",
    "y_hat_test_class = np.where(y_hat_test<0.5, 0, 1)\n",
    "\n",
    "\n",
    "test_accuracy= np.sum(y_train.reshape(-1,1)==y_hat_test_class) / len(y_test)\n",
    "\n",
    "print(\"Test Accuracy {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
